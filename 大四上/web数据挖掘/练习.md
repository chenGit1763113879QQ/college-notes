# 练习

## 第二章 MapReduce

ppt chap 2 page 104-105

选择题：下列哪些计算不适合并行计算？D

- A 计算从 1-N 的素数
- B 计算西游记小说里，“唐僧”出现次数
- C 根据销售数据，寻找和你买东西相似的人群
- D 网站计算**当前时刻**某产品的抢购数量

下列说法正确的是：D

- A. MapReduce 不是计算向数据靠拢的方式
- B. MapReduce 需要程序员掌握大量的系统知识，编程难度相对较大
- C. 可以并行计算并且需要实时计算的任务可以用 MapReduce 计算
- D. 矩阵 M 乘以向量 v，如果 v 不能放入内存，MapReduce 也可以计算

计算一个社交网站每个用户的朋友数，需要的关系运算为： C
A. 并 B. 选择 C. 分组和聚合 D. 自然连接

### 第三章 相似项发现

计算三个集合 A={1,2,3,4}, B={2,3,5,7}和 C={2,4,6}两两之间的 Jaccard 相似度。

SIM(A,B)=2/6 SIM(A,C)=2/5 SIM(B,C)=1/6

计算三个包 A={1,1,1,2}, B={1,1,2,2,3}和 C={1,2,3,4}两两之间的 Jaccard 相似度。

SIM(A,B)=3/9 SIM(A,C)=2/8 SIM(B,C)=3/9

## 第五章 链接分析

### 1.选择题：

下面说法正确的是（）
C

- A 如果转移矩阵分割成$k\times k$块，系数矩阵存储方式不需要改变
- B PageRank 的计算一般不采用迭代的方法
- C 分块计算 PageRank 的方式会增加 v 的读取次数
- D PageRank 计算不要考虑不再 MapReduce 框架之外的方式

### 2.选择题：

下列说法错误的是()
B

- A 转移矩阵每一列的和为 1
- B 面向主题的 PageRank 不需要了解用户任何信息
- C 网页有两种属性：重要性和导航性
- D PageRank 值的大小衡量了网页的重要性

### 3.选择题：

下面说法正确的是（）
C

- A Google 的算法可以完全杜绝网页搜索作弊者
- B PageRank 是 Google 搜索引擎的唯一算法
- C 经过足够多次网页冲浪，停留概率大的网页的重要性较高
- D 垃圾农场中的可达网页是作弊者完全控制的网页

### 4.判断题：

删除终止点得到的 PageRank 的值任然可以被认为是随机冲浪者的概率分布
**错**

只能衡量重要性，不能认为是概率分布

### 5.计算题：

写出下图对应的转移矩阵，并计算初始概率分布向量为[1/3,1/3,1/3]时下一步的概率分布向量

![](../pics/1.png)

转移矩阵为：

$$
M=\begin{bmatrix}
   \frac{1}{3} & \frac{1}{2} & 0 \\
   \frac{1}{3} & 0           & \frac{1}{2}\\
   \frac{1}{3} & \frac{1}{2} & \frac{1}{2}
\end{bmatrix}
$$

初始概率分布向量为[1/3,1/3,1/3]时下一步的概率分布向量为

$$
\vec{v'}=M\vec{v}
$$

$$
\begin{bmatrix}
a\\b\\c
\end{bmatrix}
=
M
\cdot
\begin{bmatrix}
\frac{1}{3}\\
\frac{1}{3}\\
\frac{1}{3}
\end{bmatrix}
=
\begin{bmatrix}
\frac{5}{18}\\
\frac{5}{18}\\
\frac{4}{9}
\end{bmatrix}
$$

## 第六章 频繁项集

### 1.判断题：

频繁项集不可以用于生物标志物关联（）
错

### 2.选择题：

下列哪个指标衡量关联规则的“有可能”程度（）
C

- A 支持度
- B 兴趣度
- C 可信度
- D 错误率

### 3.判断题：

在购物篮模型中，购物篮的数量应远大于购物篮中项的数量（）
对

### 4.判断题：

频繁项集不可以用于生物标志物关联（）
错

### 5.计算题：

针对以下购物篮数据，假设支持度阈值为 3
请按照**A-priori 法**，计算该数据的二元素频繁项集。

| Transactions | Items                      |
| ------------ | -------------------------- |
| 1            | Bread, Jelly,Peanut,Butter |
| 2            | Bread,Butter               |
| 3            | Bread,Jelly                |
| 4            | Bread,Milk,Butter          |
| 5            | Chips,Milk                 |
| 6            | Bread,Chips                |
| 7            | Bread,Milk                 |
| 8            | Chips,Jelly                |

空集是任何集合的子集，因此空集的支持度为 8。

#### 第一遍扫描

| iterm  | number | count | x   |
| ------ | ------ | ----- | --- |
| Bread  | 1      | 6     | 1   |
| Jelly  | 2      | 3     | 2   |
| Peanut | 3      | 1     | 0   |
| Butter | 4      | 3     | 3   |
| Milk   | 5      | 3     | 4   |
| Chips  | 6      | 3     | 5   |

#### 第二遍扫描

检查所有项的计数值，以确定哪些项构成单元素频繁项集。对于 A-Priori 算法的第二遍扫描，我们会只给频繁项重新编号，编号范围是 1 到 m。

|       | 项集           | 支持度 |
| ----- | -------------- | ------ |
| {1,2} | {Bread,Jelly}  | 2      |
| {1,3} | {Bread,Butter} | 3      |
| {1,4} | {Bread,Milk}   | 2      |
| {1.5} | {Bread,Chips}  | 1      |
| {2,3} | {Jelly,Milk}   | 0      |
| {2,4} | {Jelly,Chips}  | 1      |
| {2.5} | {Jelly,Butter} | 1      |
| {3,4} | {Butter,Milk}  | 1      |
| {3,5} | {Butter,Chips} | 0      |
| {4,5} | {Milk,Chips}   | 1      |

所以该数据的二元素频繁项集有：

1. {Bread,Butter}
